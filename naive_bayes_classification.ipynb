{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "548f8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Athavaloshan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f17f1540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '000063' ... 'ñskyl' 'óeur' 'úo']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"just plain boring\" , \"entirely predictable and lacks energy\" , \"no surprises and very few laughs\" ,\\\n",
    "\"very powerful\",\\\n",
    "\"the most fun film of the summer\"]\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "corpus = df[\"Sentence\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "word_count_array = X.toarray()\n",
    "words = vectorizer.get_feature_names_out()\n",
    "print((words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d17c2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.label\n",
    "unique_labels = set(labels)\n",
    "unique_labels = list(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a13c4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_count = pd.DataFrame(index=unique_labels, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e399350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 2 0]]\n",
      "[1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 0 0 1 0 1]\n",
      "5 20\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "5 20\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "5 20\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "5 20\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "5 20\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    index_arr = df.index[df['Sentiment'] == label].tolist()\n",
    "    x,y = word_count_array.shape\n",
    "    print(x,y)\n",
    "    sum = [0]*y\n",
    "    for index in index_arr:\n",
    "        sum = word_count_array[index]  + sum\n",
    "        \n",
    "    df_word_count.loc[label][:] = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "afa0996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "pos : 3.2801672885317154e-05\n",
      "neg : 6.10624872786485e-05\n",
      "result :  neg  score :  6.10624872786485e-05\n"
     ]
    }
   ],
   "source": [
    "doc = [\"predictable with no fun\"]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(doc)\n",
    "word_count_array = X.toarray()\n",
    "words_test = vectorizer.get_feature_names_out()\n",
    "\n",
    "from collections import Counter\n",
    "label_count = Counter(labels)\n",
    "print(len(labels))\n",
    "\n",
    "result = \"\"\n",
    "max_score = 0\n",
    "\n",
    "for label in unique_labels:\n",
    "    p = label_count[label]/len(labels)\n",
    "    for word in words_test:\n",
    "        \n",
    "        if word not in (words): continue\n",
    "        p = p * (df_word_count.loc[label][word] + 1)/(df_word_count.loc[label].sum() + len(words) ) \n",
    "    if (p > max_score):\n",
    "        max_score = p\n",
    "        result = label\n",
    "\n",
    "    print(label, \":\",p)\n",
    "    \n",
    "print(\"result : \", result, \" score : \", max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d22418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
